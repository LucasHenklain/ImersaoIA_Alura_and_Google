{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8M78hi/5hv2/pxKR+m8qb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasHenklain/ImersaoIA_Alura_and_Google/blob/main/ImersaoIA_Alura_and_Google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do Google"
      ],
      "metadata": {
        "id": "CsbXk9M9-4L6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5ZSePtuXTu7J"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import SupportsAbs\n",
        "import google.generativeai as genai\n",
        "\n",
        "SupportsAbs_API_KEY=\"COLOQUE SUA API Gemini AQUI\"\n",
        "genai.configure(api_key=SUA_API_KEY)"
      ],
      "metadata": {
        "id": "AbsYM42U_M3N"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "PvTviDHf_eTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "-47Wg__H_gqW",
        "outputId": "5162beed-3c9a-49e9-be09-e0a2c4980954"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurando modelo"
      ],
      "metadata": {
        "id": "2OzeQMi_CMi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "AzzSdSAKBCgN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\",\n",
        "    }"
      ],
      "metadata": {
        "id": "gQmlTpqDBgFi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo"
      ],
      "metadata": {
        "id": "P47Mn9IvCaNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "USw4Ngj0CczF"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o Projeto"
      ],
      "metadata": {
        "id": "DBLWDTt5bVlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Dados fictícios para treinamento e teste\n",
        "conjunto_treinamento = [\n",
        "    (\"Eu amo este produto! É incrível.\", \"positivo\"),\n",
        "    (\"Este produto é terrível. Não recomendo.\", \"negativo\"),\n",
        "    (\"Não sei o que dizer sobre este produto.\", \"neutro\"),\n",
        "    (\"Fiquei impressionado com a qualidade deste produto.\", \"positivo\"),\n",
        "    (\"O suporte ao cliente é péssimo.\", \"negativo\"),\n",
        "    (\"O preço é justo para o que você recebe.\", \"neutro\")\n",
        "]\n",
        "\n",
        "conjunto_teste = [\n",
        "    (\"Estou muito satisfeito com minha compra.\", \"positivo\"),\n",
        "    (\"A entrega foi muito atrasada.\", \"negativo\"),\n",
        "    (\"Este produto atendeu às minhas expectativas.\", \"positivo\"),\n",
        "    (\"Não tive uma boa experiência com este produto.\", \"negativo\"),\n",
        "    (\"O produto chegou danificado.\", \"negativo\"),\n",
        "    (\"A descrição do produto estava imprecisa.\", \"neutro\")\n",
        "]\n",
        "\n",
        "# Definir conjuntos de treinamento e teste\n",
        "dados_treinamento, rotulos_treinamento = zip(*conjunto_treinamento)\n",
        "dados_teste, rotulos_teste = zip(*conjunto_teste)\n",
        "\n",
        "# Converter rótulos para numéricos\n",
        "rotulos_dict = {\"positivo\": 0, \"neutro\": 1, \"negativo\": 2}\n",
        "rotulos_treinamento = [rotulos_dict[r] for r in rotulos_treinamento]\n",
        "rotulos_teste = [rotulos_dict[r] for r in rotulos_teste]\n",
        "\n",
        "# Criar tokenizador\n",
        "tokenizador = Tokenizer()\n",
        "tokenizador.fit_on_texts(dados_treinamento)\n",
        "\n",
        "# Pré-processar texto\n",
        "sequencias_treinamento = tokenizador.texts_to_sequences(dados_treinamento)\n",
        "sequencias_teste = tokenizador.texts_to_sequences(dados_teste)\n",
        "\n",
        "# Preencher ou truncar sequências para comprimento fixo\n",
        "comprimento_maximo = 20\n",
        "sequencias_treinamento = keras.preprocessing.sequence.pad_sequences(sequencias_treinamento, maxlen=comprimento_maximo)\n",
        "sequencias_teste = keras.preprocessing.sequence.pad_sequences(sequencias_teste, maxlen=comprimento_maximo)\n",
        "\n",
        "# Definir modelo\n",
        "num_palavras = len(tokenizador.word_index) + 1\n",
        "num_classes = 3\n",
        "modelo = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=num_palavras, output_dim=100, input_length=comprimento_maximo),\n",
        "    keras.layers.GlobalAveragePooling1D(),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar modelo\n",
        "epocas = 10\n",
        "tamanho_lote = 32\n",
        "modelo.fit(sequencias_treinamento, np.array(rotulos_treinamento), epochs=epocas, batch_size=tamanho_lote, validation_split=0.2)\n",
        "\n",
        "# Avaliar modelo\n",
        "acuracia = modelo.evaluate(sequencias_teste, np.array(rotulos_teste))\n",
        "print(\"Acurácia do modelo:\", acuracia)\n",
        "\n",
        "# Função para obter informações da API Gemini\n",
        "def obter_informacoes_gemini(texto: str, api_key: str) -> dict:\n",
        "    # Implementação para obter informações da API Gemini usando a chave de API\n",
        "    pass\n",
        "\n",
        "# Função para enviar feedback para a API Gemini\n",
        "def enviar_feedback_gemini(feedback: str, api_key: str) -> bool:\n",
        "    # Implementação para enviar feedback para a API Gemini usando a chave de API\n",
        "    pass\n",
        "\n",
        "# Exemplo de como usar as funções\n",
        "api_key = \"SUA_API_KEY_AQUI\"\n",
        "texto = \"Exemplo de texto para análise\"\n",
        "informacoes = obter_informacoes_gemini(texto, api_key)\n",
        "print(\"Informações da API Gemini:\", informacoes)\n",
        "\n",
        "feedback = \"Feedback sobre o resultado da análise\"\n",
        "sucesso = enviar_feedback_gemini(feedback, api_key)\n",
        "print(\"Feedback enviado com sucesso:\", sucesso)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAvERG6ocvNw",
        "outputId": "6ed72391-6ee2-408a-eac4-a4c0ad9d2857"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 829ms/step - loss: 1.0954 - accuracy: 0.5000 - val_loss: 1.1136 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0890 - accuracy: 0.5000 - val_loss: 1.1204 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0831 - accuracy: 0.5000 - val_loss: 1.1265 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0776 - accuracy: 0.5000 - val_loss: 1.1326 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0720 - accuracy: 0.5000 - val_loss: 1.1390 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0666 - accuracy: 0.5000 - val_loss: 1.1456 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0615 - accuracy: 0.5000 - val_loss: 1.1525 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0566 - accuracy: 0.5000 - val_loss: 1.1596 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0517 - accuracy: 0.5000 - val_loss: 1.1666 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0466 - accuracy: 0.5000 - val_loss: 1.1736 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0985 - accuracy: 0.3333\n",
            "Acurácia do modelo: [1.0985403060913086, 0.3333333432674408]\n",
            "Informações da API Gemini: None\n",
            "Feedback enviado com sucesso: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2T3OD3nTeh3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}